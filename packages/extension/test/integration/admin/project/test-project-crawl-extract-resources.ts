import TestUtils from 'get-set-fetch/test/utils/TestUtils';
import { assert } from 'chai';
import { join, resolve } from 'path';
import BrowserHelper from '../../../helpers/BrowserHelper';
import { Page } from 'puppeteer';
import CrawlHelper from '../../../helpers/CrawlHelper';
import ProjectHelper from '../../../helpers/ProjectHelper';

/* eslint-disable no-shadow */
describe('Project Crawl Extract Resources', () => {
  let browserHelper: BrowserHelper;
  let page: Page;

  const targetDir = join(__dirname, '..', '..', '..', 'tmp');

  const actualProject = {
    name: 'projectA',
    description: 'projectA description',
    url: 'https://www.sitea.com/index.html',
    opts: {},
    // directly set scenarioId and overwrite pluginDefinitions normally generated by a scenario instance
    scenarioId: 1,
    pluginDefinitions: [
      {
        name: 'SelectResourcePlugin'
      },
      {
        name: 'ExtensionFetchPlugin'
      },
      {
        name: 'ExtractUrlPlugin',
        opts: {
          extensionRe: '/^(html|htm|php|png)$/i'
        }
      },
      {
        name: 'ImageFilterPlugin'
      },
      {
        name: 'UpdateResourcePlugin'
      },
      {
        name: 'InsertResourcePlugin'
      }
    ]
  };

  const expectedResources = [
    { url: 'https://www.sitea.com/index.html', mediaType: 'text/html', info: {} },
    { url: 'https://www.sitea.com/pageA.html', mediaType: 'text/html', info: {} },
    { url: 'https://www.sitea.com/pageB.html', mediaType: 'text/html', info: {} },
    { url: 'https://www.sitea.com/img/imgA-150.png', mediaType: 'image/png', info: { width: 150, height: 150, name: 'imgA-150.png' } },
    { url: 'https://www.sitea.com/img/imgB-850.png', mediaType: 'image/png', info: { width: 850, height: 850, name: 'imgB-850.png' } }
  ];

  before(async () => {
    browserHelper = await BrowserHelper.launch();
    page = browserHelper.page;
  });

  afterEach(async () => {
    // cleanup fs
    TestUtils.emptyDir(targetDir);

    // move to admin page
    await browserHelper.goto('/projects');

    // delete existing projects
    const existingProjects = await page.evaluate(() => GsfClient.fetch('GET', 'projects'));
    if (!existingProjects) return;
    const projectIds = existingProjects.map(existingProject => existingProject.id);
    await page.evaluate(projectIds => GsfClient.fetch('DELETE', 'projects', { ids: projectIds }), projectIds);
  });

  after(async () => {
    await browserHelper.close();
  });

  async function waitForCrawlComplete(adminPage, siteId, resolve = null) {
    // if no promise defined return one
    if (!resolve) {
      return new Promise((resolve) => {
        setTimeout(waitForCrawlComplete, 5000, adminPage, siteId, resolve);
      });
    }

    const notCrawledResources = await page.evaluate(siteId => GsfClient.fetch('GET', `resources/${siteId}/notcrawled`), siteId);

    // crawl complete, there are no more resources to be crawled
    if (notCrawledResources.length === 0) {
      resolve();
    }
    else {
      setTimeout(waitForCrawlComplete, 5000, adminPage, siteId, resolve);
    }

    return null;
  }

  async function checkCrawledResources(siteId) {
    const actualResources = await CrawlHelper.getCrawledResources(page, siteId);
    assert.sameDeepMembers(actualResources, expectedResources);
  }

  async function downloadAndCheckCsv(project) {
    const generated = await ProjectHelper.downloadProjectCsv(page, project, targetDir);

    // check file content
    const expectedHeader = 'url,mediaType';
    const expectedBody: string[] = expectedResources
      .map(
        resource =>
        [JSON.stringify(resource.url), JSON.stringify(resource.mediaType)].join(',')
      );

    assert.strictEqual(generated.header, expectedHeader);
    assert.sameDeepMembers(generated.body, expectedBody);
  }

  async function downloadAndCheckZip(project) {
    const actualEntries = await ProjectHelper.downloadProjectZip(page, project, targetDir);
    const expectedEntries = ['imgA-150.png', 'imgB-850.png'];
    assert.sameDeepMembers(actualEntries, expectedEntries);
  }

  it('Test Crawl Project Extract Resources', async () => {
    // open project list
    await browserHelper.goto('/projects');

    // create project to crawl
    await page.evaluate(project => GsfClient.fetch('POST', 'project', project), actualProject);
    const projects = await page.evaluate(() => GsfClient.fetch('GET', 'projects'));
    assert.strictEqual(1, projects.length);
    const loadedProject = projects[0];
    const loadedSites = await page.evaluate(projectId => GsfClient.fetch('GET', `sites/${projectId}`), loadedProject.id);
    assert.strictEqual(1, loadedSites.length);
    const loadedSite = loadedSites[0];

    // reload project list
    await browserHelper.goto('/projects');
    const crawlInputId = `input#crawl-${loadedProject.id}[type=button]`;
    await page.waitFor(crawlInputId);

    // start crawling project
    await page.click(crawlInputId);

    // wait for all resources to be crawled (resource.crawledAt is updated for all resources)
    await CrawlHelper.waitForCrawlComplete(page, loadedSite.id);

    // check crawled resources
    await checkCrawledResources(loadedSite.id);

    // reload project list
    await browserHelper.goto('/projects');
    page.bringToFront();

    // goto project results page
    const resultsInputId = `input#results-${loadedProject.id}[type=button]`;
    await page.waitFor(resultsInputId);
    await page.click(resultsInputId);

    // start a CDPSession in order to change download behavior via Chrome Devtools Protocol
    const client = await page
      .target()
      .createCDPSession();
    await client.send('Page.setDownloadBehavior', {
      behavior: 'allow',
      downloadPath: resolve(targetDir)
    });

    // download and check csv
    await downloadAndCheckCsv(loadedProject);

    // download and check zip
    await downloadAndCheckZip(loadedProject);
  });

});
